# Microsoft Sentinel Deployment (WIP!)

_Abstract_—Microsoft Sentinel is a cloud-based Security Information Events Management (SIEM) software that can connect to multiple data sources from an existing Azure tenant security services. Those services can operate both in the cloud and on-premises. As security threats against cloud services increase, manual, reactive responses using existing services to respond to threat alerts are no longer suitable. Instead of hiring more security operations staff to react and handle alerts, our solution incorporates Microsoft Sentinel’s Security Orchestration, Automation and Response (SOAR) feature to reduce the workload on security teams and mitigate threats by acting proactively using automation based on machine learning and artificial intelligence. Sentinel also combines fragmented security analysis reports into one unified dashboard, allowing security teams to take action from a single service rather than multiple services.

_Keywords_—Cloud Computing, Cybersecurity, SIEM, SOAR, Threat Intelligence, Incident Response

## I.	INTRODUCTION
As more and more organisations transition to the public cloud, attackers are looking for new methods to exploit vulnerabilities in these systems. Microsoft Azure is a cloud computing service that is affected by this problem. With the existing services that our organisation uses to monitor and protect Azure services, such as Microsoft Defender and Active Directory Identity Protection, we have multiple dashboards where the security team needs to monitor alerts. As the company grows, threats and alerts will continue to increase; it is impossible for a manual, reactive response as too many services generate incidents in a short amount of time. Security staff will be unable to respond to all of them. We need an innovative solution to proactively respond to incidents such that it can automatically handle common threats and operate without human intervention. 
One major issue is that, traditionally, security teams in an organisation are allocated certain parts of a security domain. These domains are segregated entities in an organisation, such as applications, data, endpoints, and identity. Such a design results in fragmented and slow responses as each team can only manage its allocated domain [1]. As attacks become more sophisticated, a single threat can now span multiple security domains, and it is crucial that we can connect the threats from multiple domains to ensure a proper response.

SIEM, or Security Information Events Management, is a technology solution that allows an organisation to detect threats more efficiently. It incorporates the idea of bringing all security incidents into a single solution so the information is aggregated and can be used to correlate and respond to a security event more effectively. The main functions of a SIEM are event logging, threat management, and threat analysis. While more sophisticated SIEM solutions have additional features, such as using machine learning and artificial intelligence to group incidents, our organisation currently uses four main SIEM solutions as part of its threat management solution. They are:
-	Microsoft Defender for Cloud
-	Microsoft Defender for Office 365
-	Microsoft Active Directory Identity Protection
-	Microsoft Defender for Endpoint

Microsoft Defender for Cloud monitors our organisation's cloud resources on Azure; it can pick up malicious or suspicious actions performed on resources and detect malware on VMs (Virtual Machines). Microsoft Defender for Office 365 ensures the security of Exchange, SharePoint and Teams. For example, Office 365 can detect malicious attachments and phishing attempts in Exchange [2].
Having multiple SIEM solutions is an obvious flaw because of incidents coming from multiple sources; this results in multiple locations to find and investigate them. It can also result in overlapping incidents as attacks get more sophisticated, resulting in alert fatigue. Alert fatigue occurs when the security team deals with too many incidents, resulting in dismissed incidents. Each service also has its own investigation methods that are incompatible with the other services. Some services, such as Microsoft Defender for Endpoint, have their own automated investigation and response service, although this is an additional paid service. However, the biggest issue with the current security setup is that the existing services do not communicate with each other. So we cannot correlate incidents from different services even if they are from the same threat. While those services have more features than just SIEM, they generate alerts and incidents as a SIEM would. 

The project goal is to find a solution to unify the existing SIEM services so that the security team has the ability to predict, detect, and respond to threats more efficiently. At the same time, comply with best practices in incident management as defined by ISO/IEC 27035.

The organisation of this paper is as follows. In section two, we do a literature review and explore existing and proposed cybersecurity incident management solutions. In section three, we propose a design for our SIEM solution based on the ideas found in our literature review. In section four, we discuss the implementation and results of the project during the internship. Finally, in section five, we reflect on the internship and discuss the challenges, lessons learned, and application of knowledge during the project development. 

## II.	LITERATURE REVIEW
SIEM plays a significant role in an organisation’s cybersecurity capabilities. One of the main issues with SIEM is the large amount of data coming in for the SOC (Security Operations Centre) to handle. A manual response to an event may be too slow, especially if the security team is overwhelmed with alerts. If a security team does not use any automated alerting system, then a response could take even longer as manual security data analysis is required. We will look at existing and proposed ideas that can resolve this issue; they mainly fall under the rough categories of response methods, improving visualisation, and using automation. 

### A.	Incident Response Methods
Tondel et al. [3] investigated SIEM response management and looked into several existing practices for responding to incidents. They identified that current industry incident response methods are based on ISO/IEC 27035 standards. The standards are based on multiple phases before, during and after an incident. 

#### 1)	Plan and Prepare
The first phase begins with plan and prepare before incidents occur. An organisation should document response approaches and define or categorise incidents that have occurred, preparing for the worst. It should set up manuals to identify steps to take when incidents occur. Establish employee awareness and training to prevent threats from occurring in the first place. It is also important to define roles in the incident response process [4] to reduce overlapping roles while increasing response efficiency and preventing panic and confusion. It is also recommended to have rehearsals based on common and uncommon security incidents so that the security teams are not inexperienced when an incident does occur [5].

Hove et al. identified several solutions used by organisations to achieve this standard. Organisations tend to look at incidents as something that is ‘unwanted’. As part of planning and preparing, we should create documentation for common or predictable incidents first and then allocate them a severity label. It is also because common incidents already have solution methods, whether from the community or from experience. For example, phishing and spam are common occurrences in an organisation, and there exist defined resolution methods for those incidents. An organisation should also review CVE (Common Vulnerabilities and Exposures) from cybersecurity organisations to prepare for unexpected attacks. CVE incidents are updated regularly and come with detailed information on each attack. In the case of using Azure, Microsoft CVE is an excellent go-to method for identifying and understanding risks before they occur [1].

#### 2)	Detection and Reporting
The organisation should have the ability to detect security weaknesses and incidents by setting up monitoring that can be manual or automated. It should also gather user feedback by having a feedback reporting system. Even though monitoring tools are expensive and require significant effort to set up, it is crucial for detecting problems within an organisation [6]. It is not enough to simply ask security staff to check on specific services at set durations; this is usually not feasible. Collecting information is one crucial step in this phase; in order for an organisation to find issues with its services, it needs to be able to find patterns in what is considered regular operation. That way, abnormal behaviour can be detected; this is very important in cybersecurity, where false positives are prevalent. Data is a significant factor in being able to identify and tirage incidents. The more information you have on the incident, the more likely the organisation can respond and resolve those incidents. Finally, it is vital to document incidents when they are found so that improvements can be made in the future. Collecting historical incidents is essential, especially with the rise of artificial intelligence and machine learning, where monitoring systems can learn from incidents over time and improve response times. 

In essence, the organisation should learn from the incidents and adjust detecting and reporting methods. For example, incidents like spam may occur significantly more than phishing. However, spam is easy to detect, and phishing is not; phishing is usually detected as spam due to its similar penetration method. The organisation needs to ensure that detection systems are not generating too many alerts that can result in alert fatigue [7]. In the case of spam and phishing, phishing is significantly more of an issue than spam. However, suppose a detection system generated a large number of alerts about spam. In that case, the security team may ignore all the similar alerts and miss out on a phishing attempt on an employee. A balance of grouping alerts and using severity levels is generally a good idea to prevent alert fatigue.
All employees of an organisation play a part in detection and reporting. Not all incidents can be detected using software, so there must be procedures to ensure incidents can be reported. These include using forms or having a service desk available during work hours so the organisation's security team can respond to undetected incidents. 

#### 3)	Assessment and Decision
The organisation should have the ability to decide if an incident occurred and have the ability to classify the incident. Knowing what is normal in a system is essential to mitigate false positives. We also need to be able to triage incidents based on their severity and threat to the operations of the organisation. As incidents occur, the security team should not rely on a first-in, first-out resolution method. Critical threats may be delayed and cause more problems than low-severity incidents. By triaging incidents, the organisation can find a way to resolve high-severity incidents first and then focus on lesser-severity incidents.
Once the incident has been classified, the incident must be given to the right people to resolve. A formal procedure should be set up to ensure the right person is resolving the incident based on the classification of the incident. That is why it is vital to triage the incident so that the relevant person can handle the response [8]. Some organisations have teams for each security domain, while other organisations have one team that handles everything. It will all depend on the organisation during the plan and prepare phase; while no method is better than the other, it is important that when resolving an incident, roles do not overlap, which can reduce efficiency. 

Good workflows developed in the plan and prepare phase significantly assist the organisation’s ability to resolve incidents quickly. Detecting incidents and retrieving as much data as possible about the incident is also crucial to incident resolution. In case of issues with resolving the incident, contingency plans should be implemented to mitigate financial and reputation loss. Organisations tend not to assess every incident due to alert fatigue and can often cause critical incidents to be missed. We will look at proposed and existing solutions to reduce alert fatigue later in this section.

#### 4)	Responses
Organisations need to decide whether to respond immediately or later, depending on the classification of the incident. Knowing what or who triggered the alert from the retrieved data is crucial. Make sure to keep an eye on the source that triggered the alert. If a user triggers an alert, ensure that communication is maintained with the user to prevent further compromise to themselves or the organisation [5]. For other responses, the organisation should use forensic analysis to identify the trigger and find as much data as possible about the incident. If there are knowledge gaps or a resolution is not possible, the organisation should consider external assistance. External knowledge can be helpful, especially when using third parties that have experience resolving similar incidents. Communication is also important in the response and ensures that the incident should be escalated if necessary. 

Using some sort of tracking system would also benefit a response, as a team can view the progress of the response to prepare for any further steps. As part of tracking, forensics is also an important step in the incident response process. Forensic tools are beneficial in identifying the incident’s root cause, making resolving incidents more efficient and preventing future events [9]. Generally, forensic tools can link data together, produce a clearer picture of the incident, and give a deeper understanding. 

Response techniques can also differ, depending on the incident security. High-severity incidents may require third parties, such as police [10], in events of data compromise or other privacy breaches. High-severity incidents can also be internally resolved. Less severe incidents should be reduced as incidents occur since these incidents can potentially be resolved automatically, especially if it is repetitive. Examples include blocking spam or preventing external users from emailing attachments. Automation should be considered, especially around repetitive incidents; this way, security teams can be tasked with more complex and crucial tasks. 

#### 5)	Lessons Learnt
Learning from incidents is crucial to preventing them from occurring again. By doing forensics and tracking the response, organisations can identify the root causes of the incident and proceed with actions to prevent it from happening again. Incident responses can be automated, such as setting up blocking rules for an internet firewall or having a blocking list of email addresses. Additionally, the resolution process should be well documented so that future security teams in the organisation can efficiently resolve the incident. We also need to ensure employees do not trigger the same alerts by having frequent employee cybersecurity training and awareness.

Once the incident has been resolved, the organisation should review or look into further forensic analysis. The data from the incident investigation should be kept for future reference and, in recent times, for machine learning automation. The organisation should also share its findings with the community to prevent similar incidents or attacks. Sharing data can also allow organisations to learn from each other and improve their response, especially if more than one organisation has had the same incident. 

### B.	Data Visualisation
To increase the efficiency of a security response, improving the overall visualisation of the organisation’s security posture is important. Security teams are easily distracted by a large amount of information. Separating incidents and visualisation is vital to ensure security teams can see critical information and respond to high-severity incidents as soon as possible. 

Novikova et al. [11] have proposed an architecture to improve the graphical user interface, especially regarding attack modelling. That way, SOC staff can easily view information important to threat responses and ensure that large amounts of data do not distract the SOC team. Their design will require monitoring real-time data, working with historical events, setting rules for risk identification, and representing the output in an ‘effective’ graphical interface to manage security incidents and resources.

Marty et al. [12] have suggested the primary use of cyber security reporting by including monitoring and historical data to be displayed for perimeter monitoring security teams. For each team, different graphs should be used. However, data should not always be shown as a table, but instead use histograms, linear, and radial charts to prevent visual cluttering. It is also recommended to display different types of organisation infrastructure and the attack methods associated with a count or summation. Marty et al.’s recommendations are used in many organisations’ SIEM monitoring and visualisation system, such as a security posture dashboard.
Information security dashboards in SIEM should be displayed in a way that gets the most critical information across first and should have a priority display method, such as incidents first, before general data. Another approach is to group data into graphs by each role or technique. Tables or textual data should be for detailed analysis and not for ‘at a glance’ purposes. 

Lakkaraju et al. [13] propose using scatter plots to monitor information flow to better show a cyber-attack taking place. Scatter plots are also recommended to be used for network port activity, such as network activity between local and global networks.

Overall, the summarised visualisation recommendation includes the following:
-	Real-time data 
-	Historical data
-	Security alerts/incidents
-	Attack modelling
-	Actions that were taken to mitigate risks
-	Resources used by the organisation

Graphs were more recommended than data tables, allowing faster recognition and understanding of the data as a high-level overview. Data visualisation recommendations go hand in hand with alert fatigue reduction because we need to ensure we display information in a way that does not draw the viewer’s attention from something important. 

### C.	Automation/SOAR (Security Orchestration, Automation, and Response)
With our SIEM solution, we need to improve response times and prevent alert fatigue. One solution is to use automation; while automation is very broad, in the SIEM sense, it is about being proactive to cybersecurity threats rather than reactive when they occur. Current SOC teams that use manual surveillance suffer from this issue; only when an incident occurs does the security team respond. Automation can allow a response immediately or even before a threat takes hold.

While simple automation methods can be set up easily by a security team using standard SIEM software, a need to improve accuracy and reactiveness is to use machine learning. Event correlation is a great solution that can improve an automated response. Event correlation uses machine learning to find similarities in events and find common attack methods or entities affected to derive a greater coverage of different but similar incidents that normal security software may not be able to pick up [14]. With event correlation set up, automation rules can react significantly quicker than a human response. However, automated responses must be reviewed to ensure they respond correctly and are not overreacting, such as during a false positive [15].

Data retrieval into a SIEM solution can also be automated. Pavlik et al. propose using a push-and-pull method to retrieve and export data from SIEM systems. A pull method can use the standard Syslog protocol, which is based on reporting logs created by a system that can be used for debugging or for cybersecurity purposes; it can also be used for security analysis. Some methods use REST API (Representational State Transfer Application Programming Interface) to send and receive data. Pull methods are considered safer because the SOC team sets them up so the data is trustworthy. Although SIEM aggregates data for a more efficient response, the SIEM system may not retrieve the latest information as soon as it is generated by other systems, which is a disadvantage. It is important to ensure that reporting systems are compatible and use push methods that the SIEM system can pull in automatically within a reasonable amount of time, preferably as soon as it is generated.

SOAR systems should not generate logs by themselves. Instead, they should receive data generated by other systems. With that data, the SOAR system processes the logs and determines actions. Data should also be normalised so that SOAR does not have to deal with additional overheads when processing data and giving a reaction. 

To implement a successful SOAR solution, Pavlik et al. [14] propose using both a correlation engine and a rule engine. This separates the correlation step and the automation step in a SOAR system. Having a separate engine also enables independent decision-making and reduces the amount of processing power required for each engine. It also makes it easier when reviewing the autonomous system. 

### D.	Summary
Overall, SIEM and SOAR play an essential part in mitigating cybersecurity threats in an organisation. We see that technologies for these systems are improving, especially with machine learning. We saw how traditional security responses can be automated and how visualisation plays an important role in highlighting incidents while preventing alert fatigue. SOAR systems drastically improve an organisation’s security standing and its role in a security response.

## III.	DESIGN
### A.	SOAR Solution
From the literature review, it is evident that a manual response to security incidents is no longer suitable in the current environment where attacks become multi-layered and because organisations now have large digital footprints. Automation is the solution; SOAR should be used in our implementation to mitigate the workload posed on an organisation's security staff. SOAR will also allow a more cost-effective solution to the organisation and can proactively and efficiently handle threats.

Our literature review found that many authors referred to the ISO/IEC 27035 standards for a cybersecurity incident response. From ISO/IEC 27035 guidelines, I looked at the phases as described by Tondel et al. [3] and found that SOAR is a solution that can cover these phases more proactively than a manual approach.

Microsoft Sentinel is a SIEM and SOAR solution that can solve this problem; with Microsoft Sentinel, we can automate threat responses and create alerts for other incidents, even during out-of-office hours [16]. Additionally, it provides a unified platform to monitor the company’s entire cloud resources and other Microsoft services such as Exchange, SharePoint and Teams. It also has features such as threat intelligence which incorporates machine learning to identify and correlate threats. Microsoft CVE is also built into its existing SIEM services. For automation, Microsoft Sentinel uses playbooks which are Azure Logic Apps that can automate several actions. 

Microsoft Sentinel can connect with multiple Microsoft services and third-party services [17] such as Cisco and AWS (Amazon Web Services) while allowing manual connections using Syslog or REST API. Therefore, we can connect existing organisation SIEM services and bring any incidents generated by those services together. This reduces fragmented information the security team receives and allows more detailed investigations and analysis through one service. 

When comparing Microsoft Sentinel’s capabilities with ISO/IEC 27035 standards, there are many features that Microsoft Sentinel offers that satisfy the phases of each incident response. With the plan and prepare phase, Microsoft Sentinel provides automation rules which allow organisations to set up prior to an incident occurring. These automation rules can also be documented and logged when they do occur. As it is also part of the Microsoft security suite, it has access to Microsoft threat intelligence, such as a database of CVEs and historical incidents that have targeted other organisations. Using Azure Active Directory and built-in RBAC (Role Based Access Control) roles, we can assign users specific roles and permissions to determine their level of access to the Sentinel solution. Usually, one only needs to be assigned the “Microsoft Sentinel Responder” role to respond to incidents. However, depending on the organisation’s requirement, some users may be assigned elevated roles to modify the automation of Microsoft Sentinel. As with Microsoft’s advice that threats are becoming more sophisticated, Tondel et al.’s advice that specific roles need to be designed may not be suitable in the current environment. The recommended roles by Microsoft cover a range of security domains specifically targeted to mitigate these sophisticated threats.

Microsoft Sentinel satisfies the detect and report phase by using two methods. Firstly, Microsoft Sentinel gathers all data generated by the other SIEM services, and so as part of those services, existing detection methods already exist. Using the data generated from those services, Microsoft Sentinel goes one step further and combines all that data to correlate the incidents using historical data and machine learning. Forensic tools are readily available as each incident has evidence in the form of a list of entities. The list contains all the information gathered from the alerts, which can include the user, endpoint device, cloud resource, IP addresses and more.

Data from existing SIEM services are ingested using tabular data, while third-party connectors may use the Syslog standard or REST API, which may use JSON or XML. This data is stored by default for ninety days but can be extended if required. In order to detect incidents, Microsoft Sentinel uses analytic rules. Analytic rules are developed using KQL (Kusto Query Language) [18]. KQL is based on the SQL query language used for databases. Since the data is in a tabular format, an SQL-like language would be suitable. KQL allows the declaration of variables, easier time filtering, and more powerful functions to modify the output. It also can convert directly into a graph using Azure Workbooks.

The organisation can create their own KQL analytic rules or use built-in and community-created rules to cover a wide range of cybersecurity threats. Depending on the cost, some rules may be scheduled while some can be set to NRT (near-real time). NRT will consume more resources, and the organisation will be charged more. Ideally, each analytic rule should not return an output when they are run because they detect cybersecurity threats through the logs ingested into Microsoft Sentinel. If there is an output, then an incident should be created along with a severity label. By allowing organisations to create their own analytic rules and assign severity labels allows for a more personalised approach to threat detection, which can reduce false negatives and alert fatigue. Having built-in rules and a community to create additional rules also allows threat detection to be up to date. With Microsoft Sentinel, organisations can choose the ratio of their own or third-party rules. When using existing SIEM solutions, the detection rules could not be changed, so some incidents were being generated repeatedly without the ability to be turned off; analytic rules do not have this problem. Additionally, our organisation has set up a service desk for users to report directly to the security team if Microsoft Sentinel does not detect every incident. Microsoft also has built-in reporting methods, such as through Microsoft Exchange, where users can report malware or spam.

We can respond to security incidents using Microsoft Sentinel playbooks. These are Azure Logic Apps that run a series of actions or commands when a certain condition is met. The majority of playbook responses are for an immediate response to tackle threats as soon as they occur. Playbooks are set up during the planning phase to prepare for incidents and resolve them without any manual intervention. For Microsoft Sentinel, analytic rules are used to generate conditions and trigger playbooks to run. These can include alerting users, running antivirus, isolating endpoints or blocking a user altogether. 

We use automation rules to combine analytic rules and playbooks [19]. Each rule can consist of multiple analytic rules and multiple playbooks. Once an incident is generated, determining who would be suitable to resolve an incident is firstly determined by automation rules. If no automation rules are set up automatically or manually, then the incident cannot be resolved using SOAR. When an incident cannot be resolved using SOAR, the incident should be assigned to the security team. As discussed in the plan and prepare phase, Azure Active Directory can be used to assign users to the incidents when required. When using SOAR, each automation rule has a priority starting from one being the highest priority. Depending on the order of each automation rule, the incident is resolved by going through the automation rules with higher priorities first. Multiple automation rules allow the incident to be assessed by different conditions and used to determine if it can be resolved automatically, thus creating a workflow for automation. If automation cannot be used, user input is required. However, automation should significantly cover the large number of repetitive incidents preventing alert fatigue on the security team.

Every action performed by Microsoft Sentinel, such as playbooks or analytic rule outputs, are logged in the central log repository. Both ingested logs from third parties and Microsoft Sentinel’s own logs are collected here for easy analysis to satisfy the lessons learnt phase. We can learn from each of these logs. Every SIEM service from Microsoft contains an abundant amount of information about the incident and also displays the tactic used based on the MITRE ATT&CK framework [20]. There are twelve tactics in total which is used to describe a security incident. These tactics can be correlated using analytic rules or threat intelligence. Additionally, any new incident will contain a list of similar incidents retrieved from historical data. From automation, we can also view logs about how the automation closed each incident and the type of playbook that ran successfully. We can learn from the failures and successes of Microsoft Sentinel's automation and adapt or set up new automation rules that govern the automated response. Since automation rules are split into analytic rules that detect and playbooks that respond, it allows for more straightforward configuration when changes are needed.

### B.	Data Visualisation

 IMG

_Fig. 1. Built-in Microsoft Sentinel Reporting Dashboard_

From the literature review, we saw that we need improved visualisations of the organisation’s security standing to increase efficiency. It was decided that the built-in reporting dashboard shown in Fig. 1. was not suitable as it did not contain the required information we require. Since the dashboard only shows up to 24 hours of data, we need to be able to look at historical data. We also need to see how we respond to incidents.
It was decided that since all the data is ingested into Microsoft Sentinel into a single repository, we could export that data and use it in a Microsoft Power BI dashboard. Since the data in the repository was tabular, it is compatible with Power BI. Therefore, it was decided to manually create a dashboard using Power BI so that we could be able to achieve some of the recommendations in the literature review, as well as use colours for improved visualisation. It also allowed the dashboard to be used for different departments if needed and allowed reporting to be more adequate for the security team, as the built-in one is too generic. 

### C.	Additional Features
The organisation has several departments that are interested in the Microsoft Sentinel implementation. Since the implementation is done through Microsoft Azure, a cloud service, we can use infrastructure as code to deploy the implementation. Microsoft Azure Resource Manager templates are ideal for deploying Microsoft Sentinel using infrastructure as code. However, it lacks the ability to deploy more fine-tuned settings, such as data connectors and user variables. Therefore, it was decided to use Terraform. Terraform is an open-source tool that allows infrastructure as code deployment; while similar to Azure Resource Manager templates, it is not confined to Azure [21]. Terraform can be used to deploy on AWS and GCP. We chose Terraform because it had the ability to deploy fine-tuned settings in Microsoft Sentinel that Azure Resource Manager templates could not have. Terraform can also be deployed directly through Azure Cloud Shell, a command line interface directly through the browser. Being able to deploy through Azure Cloud Shell makes deployment very simple and has no disadvantages compared to Azure Resources Manager template deployment.

## IV.	IMPLEMENTATION
### A.	Microsoft Sentinel
#### 1)	Data Connectors
In order for Microsoft Sentinel to receive live data from existing services, we must first use data connectors to get them connected. The word we use is ingest, which applies to all the data coming into Microsoft Sentinel. The following services were connected to Microsoft Sentinel:
-	Azure Activity
-	Azure Active Directory Identity Protection
-	Microsoft Defender for Cloud
-	Microsoft Defender for Endpoint
-	Microsoft Defender for Office 365
-	Microsoft Defender for Cloud Apps

By bringing these services into one repository (known as a log analytics workspace), we can easily access all the data. All the services generate logs in a tabular format, so it is easy to perform KQL analysis on them.
Azure Activity generates logs for all administrative actions performed on our organisation's Azure services, including (but not limited to) creating, reading, updating, and deleting. It also ingests service health, resource health, resource alerts, autoscaling, and policy compliance. Azure Activity does not generate its own alerts as it is not a SIEM service but rather a monitoring service. Therefore, we will need analytic rules to analyse the information being ingested.

Azure Active Directory Identity Protection generates a large number of logs that includes mainly user sign-ins. Since this log generates a significant amount of redundant information, it was decided to filter the logs before ingesting them into Microsoft Sentinel, as this would also save costs. The service also generates audit logs and sign-ins from non-user entities, such as service principles, which are system-managed entities that can act on behalf of a user. It also has the ability to tell us if a user is of a certain risk. When combined with Azure Activity, we can combine user actions with a user account on Azure. 

For Microsoft Defender for Cloud, the default connection settings were used as the ingestion for that data is free. Bidirectional sync was enabled so that any alert generated in Defender for Cloud would be shown in Microsoft Sentinel and vice versa. Any changes to the data would also show up on both services. Taking cost into consideration, and the fact that it is free to ingest the data, no changes were made to this connection.
When connecting Microsoft Defender for Office 365 to Microsoft Sentinel, we looked at the useful logs and those that were unlikely to be helpful during an incident. It was decided that since Defender for Office 365 generated its own alerts, we would only need to ingest security alerts and not the entirety of Office 365 data, as this would be a cost issue. Since the security alerts generated by Defender for Office 365 would contain sufficient information about an incident, there was no need to ingest all Office activity into Microsoft Sentinel. The alerts would cover Microsoft Teams, Microsoft SharePoint and Microsoft Exchange. For example, if a malicious attachment were discovered on our organisation's email servers, Microsoft Exchange would generate a security alert containing the relevant information, such as the sender and receiver, the malicious attachment, and its file hash.

Microsoft Defender for Endpoint was a crucial data connector as endpoint devices are usually one of the first points of an attack. However, this data connector also generated too much redundant information that would create significant costs. One of the main issues was device logs; it would generate a log for any action performed on a device, whether it be a network connection or a sign-in. Therefore, considering that Defender for Endpoint generates its own alerts, we would only need to ingest the security alerts containing all the relevant information. We also discovered that since the devices used OneDrive, the information would have been uploaded to SharePoint. It was decided that to determine the cause of malware alerts, we would use SharePoint logs from Office 365 to satisfy our requirement. 

Overall, the data connectors were chosen carefully to reflect on what was practical and cost-effective. As we saw that some services already generated their own security alerts, this would save time compared to ingesting more raw data and trying to go through that data. Some connectors do not generate their own alerts, but this would still mean we need to pick the most appropriate data to use and not just import everything.

#### 2)	KQL Analytic Rules
Once the data connectors are successfully connected, and the logs can be seen being created in the log analytic workspace, KQL analytic rules can now be used to analyse and detect threats. While existing services already generate their own alerts that can be used in Microsoft Sentinel. Creating our own KQL rules can bring more personalised detection. We can use analytic rules to detect anomalies for data sources that do not generate their own alerts. For example, on Azure Activity, we can use KQL queries to detect malicious actions performed on resources, such as creating expensive VMs or changing container secrets. Combined with Active Directory, we can know who performed those actions by combining them with sign-in logs.

An analytic rule that looks for suspicious logins can be used to go through Active Directory logs and find login IP addresses. If a sign-in IP address was from outside New Zealand, it could be deemed suspicious. We can also look at finding if multiple sign-in were attempted before a successful sign-in, showing a successful brute force attack. Fig. 2 shows a few KQL analytic rules designed manually returning no outputs, meaning no threats were detected. Fig. 3 shows some built-in or community-built analytic rules which target more sophisticated attacks, such as zero-day attacks.

 IMG
 
_Fig. 2. Several manually built KQL analytic rules_

IMG
 
_Fig. 3. A list of built-in analytic rules_

Analytic rules can be set to run manually or scheduled to run at certain time intervals. NRT is more expensive than scheduled. For example, a rule that searches for suspicious administrative actions can be set to NRT. In contrast, a rule that detects password sprays can be set to run every week because all user accounts are protected by multi-factor authentication. Depending on the level of threat determines the time interval between each run.

#### 3)	Playbooks
Several playbooks were developed to create an automated response to security incidents. Some of the playbooks developed are discussed below. 
Block-AADUser-Incident: this playbook blocks a user from Active Directory. If the user can be disabled, that user's manager is contacted by going through the Active Directory list (if a manager is assigned). If the user does not have a manager, the user will be disabled. If the user has a manager, the manager will be notified before the user is blocked. This playbook incorporates the Active Directory data connector and Office 365 for sending emails.

IMG
 
_Fig. 4. The "Prompt-User-Incident" playbook with two conditions

Prompt-User-Incident (Fig. 4.): this playbook checks whether the user did an action. The playbook is connected to Active Directory and Office 365 Exchange; this also allows an email to be sent. If the user selected the option that they did the action, then the playbook would notify the SOC team that the action was done by the user, and the incident would be closed. If the user says that they did not perform the action, then a message will be sent to the SOC team to investigate the issue further. The following steps are the Prompt-User-Incident logic app flow:
1.	For each Microsoft Sentinel incident
2.	Get the user account from the logs
3.	Get the user email from Azure Active Directory
4.	Send an email to the user with two options: "It was me" or "It was not me"
5.	If the user responds with "It was me", the incident is closed, and a message to Teams is sent showing "Incident Resolved" (shown as the green box in Fig.4.).
6.	If the user responds with "It was not me", the incident is set to active, a message is sent to Teams, and a ticket is logged with the security team (shown as the red box in Fig.4.).

Run-MDEAntivirus: this playbook will force an antivirus scan on the affected endpoint computer using Microsoft Intune. The playbook has two conditions, one is to check if the hostname or device ID can be found, and it will use whichever one that can be found. The second condition then checks if the device exists; otherwise, the SOC team will be notified that the scan failed. It may be likely that the user did not have a compatible endpoint to force the antivirus scan. The process for the Run-MDEAntivirus playbook is as follows:
1.	For every Microsoft Sentinel incident
2.	Initiate an MDEDeviceId variable
3.	Get the device log from the device entities list
4.	For each device, if the ID is detected from that list, use device ID; otherwise, use device hostname 
5.	Set the MDEDeviceId variable to the detected ID or hostname 
6.	If the MDEDeviceId variable is not null, then run an antivirus scan and send a message to Teams about the success
7.	Otherwise, message Teams that the scan failed because the device ID could not be found.

#### 4)	Automation Rules
Automation rules are a combination of playbooks and analytic rules. They create an automated workflow for the response process. For example, if an endpoint triggered an incident by using an analytic rule (e.g., malware), then we can use the playbook to send an email asking if the user is doing testing on their endpoint. If the user responds that they caused the incident, it can be closed. If the user responds that they did not perform the action, then depending on the incident, the following action will be taken:
1.	Change incident status to Active
2.	Trigger a playbook that alerts the SOC Teams' chat
3.	Trigger a playbook to run antivirus on the endpoint
4.	Trigger a playbook to isolate the machine

The SOC team can manually un-isolate the device once the threat is resolved or dismiss the incident, which can trigger the playbook to un-isolate the machine automatically.

#### 5)	Summary
Overall, using analytics rules and playbooks allows multiple ways to respond using automation rules which allows either one or more analytic rules in combination with one or more playbooks to be used for incident response. Because of compatibility with structured data, different types of logs can be easily analysed and worked with.

### B.	Microsoft Power BI
 
Fig. 5. A Power BI dashboard for our organisation's security team
Once the automation was set up, it was decided to use Microsoft Power BI to create a visual overview of the security operations at our organisation. Fig. 5. shows the final product, where we used several recommendations based on our literature review. The dashboard allows a quick overview of the entire security posture of the company while using different colours to draw attention to the viewer as well as using graphs. The graphs covered the number of incidents by severity, where they were generated, the incidents over time, and the incidents by the MITRE ATT&CK tactic. It also contained the function to filter using date and time as well as calculating the average time to triage and close incidents.

### C.	Terraform
Once the Microsoft Sentinel implementation was successfully implemented, the next step was to create an infrastructure as code feature so that Microsoft Sentinel could be easily deployed into other departments. Firstly, the Azure environment needed to be set up in Terraform; this included creating resource groups, log analytic workspaces and using local variables to declare tags and the location of each deployment.
Once the skeleton was deployed successfully, programming skills from university courses assisted me with the rest of the implementation, as the structure was mainly JSON. Using Azure Resource Manager templates was also beneficial, as this was compatible with Terraform. Data connectors, analytic rules, playbooks and automation rules were all successfully written up in Terraform and were successfully deployed in one click. We can also directly use Azure Cloud Shell to deploy the Terraform code online using the Azure Portal. Overall, the result was positive, as most of the Microsoft Sentinel features could be deployed using Terraform.

### D.	Result
Once all the features of Microsoft Sentinel were set up and automated process flows were created using automation rules, the amount of security alerts decreased dramatically. Before the deployment of Microsoft Sentinel, there was a large number of repetitive alerts, accounting for around twenty daily alerts. Once we began using the Microsoft Sentinel implementation, most days had no alerts as they were all closed by SOAR. Occasionally, we would have one or two alerts that could not be handled by SOAR and would need to be manually investigated. The time to closure and the time to triage are two methods of measuring the security team’s performance. Both these values were decreased from a few days to a few hours, which is a significant improvement for the security team at our organisation. 
